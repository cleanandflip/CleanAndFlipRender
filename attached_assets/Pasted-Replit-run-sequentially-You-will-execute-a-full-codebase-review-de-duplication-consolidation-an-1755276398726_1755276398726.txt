Replit (run sequentially)
You will execute a full codebase review, de-duplication, consolidation, and guardrail installation.
Follow these steps EXACTLY and do not stop until all SUCCESS CRITERIA are met.

================================================================================
SUCCESS CRITERIA (must ALL be true before you stop)
================================================================================
- No duplicate files (by content) or near-duplicate code (by tokens/AST).
- No duplicate implementations of the same feature (cart, locality, geo, websocket, etc.).
- All imports point to canonical SSOT modules only; legacy/duplicate modules are removed.
- Unused files, unused exports, orphan routes, circular deps removed/fixed.
- Session/cart owner is unified on `connect.sid`; zero custom "sid" cookies exist.
- Cart is consolidated (no duplicate rows) and clamped to stock on read and write.
- Locality SSOT is universally applied; forbidden legacy helpers removed.
- Build & type-check & lint pass. Key smoke tests pass.
- CI guardrails block reintroduction of legacy/dup patterns automatically.

================================================================================
PHASE 0 — Branch, tooling, and baseline snapshots
================================================================================
1) Create a working branch:
   git checkout -b chore/repo-cleanse-ssot-guardrails

2) Install tooling (dev-only):
   npm i -D ts-morph @types/node jscpd knip ts-prune madge depcheck \
         eslint-plugin-import eslint-plugin-unused-imports \
         glob fast-glob cosmiconfig object-hash zod \
         @typescript-eslint/parser @typescript-eslint/eslint-plugin \
         vite-bundle-visualizer source-map-explorer

3) Baseline snapshots:
   mkdir -p audit scripts codemods .github/workflows
   node -v > audit/node-version.txt
   npm -v > audit/npm-version.txt
   npm ls --all > audit/npm-tree-before.txt || true
   git ls-files > audit/git-files-before.txt
   rg -n --no-heading -g '!node_modules' . > audit/repo-grep-snapshot.txt

4) Fast type/build check (capture status but do not stop if failing):
   npm run build || true
   npx tsc --noEmit || true

================================================================================
PHASE 1 — Define SSOT allowlist + legacy banlist (your architecture)
================================================================================
Create `audit/ssot-allow-ban.json` with EXACT content:

{
  "canonical": {
    "locality": [
      "shared/locality.ts",
      "shared/geo.ts",
      "shared/availability.ts",
      "server/services/localityService.ts",
      "client/src/hooks/useLocality.ts"
    ],
    "cart": [
      "server/routes/cart.v2.ts",
      "server/services/cartService.ts",
      "server/utils/cartOwner.ts",
      "client/src/hooks/useCart.ts",
      "client/src/lib/cartKeys.ts",
      "client/src/lib/cartApi.ts"
    ],
    "fulfillment": [
      "shared/fulfillment.ts",
      "shared/availability.ts",
      "server/utils/fulfillment.ts"
    ],
    "auth": [
      "server/auth.ts",
      "server/middleware/auth.ts",
      "client/src/hooks/use-auth.tsx"
    ],
    "websocket": [
      "server/websocket.ts"
    ],
    "envConfig": [
      "server/config/env.ts"
    ]
  },
  "legacyBan": [
    "server/routes/cart.ts",
    "server/lib/locality",
    "server/lib/localityChecker",
    "server/locality/getLocalityForRequest",
    "client/src/hooks/use-cart.tsx",
    "src/lib/locality.ts"
  ],
  "forbiddenPatterns": [
    "/api/cart(?!\\.v2)",           // any non-v2 cart endpoint
    "\\bisLocal\\(",                 // ad-hoc locality checks
    "\\bisLocalMiles\\(",
    "res\\.cookie\\(['\"]sid['\"]",  // custom cookie setter
    "document\\.cookie\\s*=\\s*['\"]sid", // client-side sid writes
    "eval\\(", "new Function\\("
  ],
  "preferPaths": [
    "^shared/",
    "^server/services/",
    "^server/utils/",
    "^client/src/hooks/",
    "^client/src/components/"
  ]
}

================================================================================
PHASE 2 — Duplicate detection (content + AST clones) and dead code scan
================================================================================
A) Exact duplicate files by content hash:
Create `scripts/find-duplicate-files.mjs`:

import fs from "fs";
import crypto from "crypto";
import fg from "fast-glob";
const include = ["**/*.{ts,tsx,js,jsx,css,scss,md,json}", "!node_modules/**", "!dist/**", "!build/**", "!coverage/**"];
const files = fg.sync(include, { dot: true });
const map = new Map();
for (const f of files) {
  const buf = fs.readFileSync(f), h = crypto.createHash("sha1").update(buf).digest("hex");
  (map.get(h) ?? map.set(h, []).get(h)).push(f);
}
const dups = [...map.entries()].filter(([,arr])=>arr.length>1).map(([h,arr])=>({hash:h,files:arr.sort()}));
fs.writeFileSync("audit/duplicate-files-content.json", JSON.stringify(dups,null,2));
console.log(`Content-duplicate groups: ${dups.length}`);

Run: node scripts/find-duplicate-files.mjs

B) Near-duplicate clones (jscpd):
npx jscpd --min-tokens 50 --reporters json --ignore "**/node_modules/**,**/dist/**,**/build/**" \
  --output audit --path .

C) Dead/unused files & exports, circular deps, dep rot:
npx knip --reporter json > audit/knip.json || true
npx ts-prune -p tsconfig.json > audit/ts-prune.txt || true
npx madge --ts-config tsconfig.json --extensions ts,tsx,js,jsx --circular --json . > audit/madge-circular.json || true
npx depcheck --json > audit/depcheck.json || true

================================================================================
PHASE 3 — Build a consolidation plan (pick canonicals, mark deletions)
================================================================================
Create `scripts/build-consolidation-plan.mjs`:

import fs from "fs";
const allowBan = JSON.parse(fs.readFileSync("audit/ssot-allow-ban.json","utf8"));
const dupContent = JSON.parse(fs.readFileSync("audit/duplicate-files-content.json","utf8"));
const jscpd = JSON.parse(fs.readFileSync("audit/jscpd-report.json","utf8"));
const knip = JSON.parse((()=>{try{return fs.readFileSync("audit/knip.json","utf8")}catch{return "{}"}})());

const prefer = allowBan.preferPaths.map(p=>new RegExp(p));
const canonicalSets = new Set([].concat(...Object.values(allowBan.canonical)));
const actions = { replaceImportsThenDelete: [], deleteSafe: [], reviewManual: [] };

const rank = f => {
  for (let i=0;i<prefer.length;i++) if (prefer[i].test(f)) return i;
  return 999;
};
const pickCanonical = files => files.sort((a,b)=> rank(a)-rank(b) || a.length-b.length)[0];

// content-duplicates
for (const grp of dupContent) {
  const canon = pickCanonical(grp.files);
  grp.files.filter(f=>f!==canon).forEach(f => actions.replaceImportsThenDelete.push({file:f, canonical:canon, reason:"content-duplicate"}));
}

// AST clones (may need manual in some cases)
if (jscpd?.duplications) {
  for (const d of jscpd.duplications) {
    const files = (d.files||[]).map(x=>x.filename);
    if (files.length<2) continue;
    const canon = pickCanonical(files);
    files.filter(f=>f!==canon).forEach(f => actions.replaceImportsThenDelete.push({file:f, canonical:canon, reason:"ast-clone"}));
  }
}

// knip unused files (not in canonical set)
if (knip && knip.files) {
  for (const f of Object.keys(knip.files)) {
    if (!canonicalSets.has(f)) actions.deleteSafe.push({file:f, reason:"knip-unused"});
  }
}

// legacy banlist
allowBan.legacyBan.forEach(p => actions.replaceImportsThenDelete.push({file:p, canonical:null, reason:"legacy-banned"}));

fs.writeFileSync("audit/consolidation-plan.json", JSON.stringify(actions,null,2));
console.log("Plan -> audit/consolidation-plan.json");

Run: node scripts/build-consolidation-plan.mjs

================================================================================
PHASE 4 — Codemods: rewrite imports to canonical modules, then purge files
================================================================================
A) Rewrite imports:
Create `codemods/replace-imports-to-canonical.ts`:

import { Project } from "ts-morph";
import fs from "fs"; import path from "path";
const plan = JSON.parse(fs.readFileSync("audit/consolidation-plan.json","utf8"));
const reps = plan.replaceImportsThenDelete.filter((x:any)=>x.canonical);
const project = new Project({ tsConfigFilePath: "tsconfig.json" });
project.addSourceFilesAtPaths(["**/*.{ts,tsx}", "!node_modules/**", "!dist/**", "!build/**"]);
function norm(p:string){ return p.replace(/\\/g,"/"); }
for (const sf of project.getSourceFiles()) {
  let changed=false;
  for (const imp of sf.getImportDeclarations()) {
    const spec = norm(imp.getModuleSpecifierValue());
    for (const r of reps) {
      const from = norm(r.file); const to = norm(r.canonical);
      const fromFile = from.split("/").pop();
      if (spec.endsWith(from) || spec.endsWith(fromFile!)) {
        const rel = path.relative(path.dirname(norm(sf.getFilePath())), to).replace(/\\/g,"/");
        imp.setModuleSpecifier(rel.startsWith(".") ? rel : "./"+rel);
        changed = true;
      }
    }
  }
  if (changed) sf.saveSync();
}
console.log("Imports rewritten where matches found.");

Run: npx ts-node codemods/replace-imports-to-canonical.ts

B) Purge files:
Create `scripts/purge-files.mjs`:

import fs from "fs";
const plan = JSON.parse(fs.readFileSync("audit/consolidation-plan.json","utf8"));
const rm = (f)=>{ try{ fs.rmSync(f,{force:true}); console.log("Deleted:", f); } catch(e){ console.warn("Could not delete", f, e?.message); } };
(plan.replaceImportsThenDelete||[]).forEach((x:any)=>{ if (x.canonical || x.reason==="legacy-banned") rm(x.file); });
(plan.deleteSafe||[]).forEach((x:any)=> rm(x.file));

Run: node scripts/purge-files.mjs

================================================================================
PHASE 5 — Enforce forbidden patterns + legacy endpoint markers
================================================================================
Create `codemods/forbidden-patterns-patch.ts`:

import { Project } from "ts-morph"; import fs from "fs";
const cfg = JSON.parse(fs.readFileSync("audit/ssot-allow-ban.json","utf8"));
const project = new Project({ tsConfigFilePath: "tsconfig.json" });
project.addSourceFilesAtPaths(["**/*.{ts,tsx}", "!node_modules/**"]);
for (const sf of project.getSourceFiles()) {
  let text = sf.getFullText(); let changed=false;
  for (const pat of cfg.forbiddenPatterns) {
    const re = new RegExp(pat, "g"); if (re.test(text)) { text = text.replace(re, (m)=>`/* SSOT: FORBIDDEN ${pat} */ ${m}`); changed=true; }
  }
  if (changed){ sf.replaceWithText(text); sf.saveSync(); }
}
console.log("Forbidden patterns annotated.");

Run: npx ts-node codemods/forbidden-patterns-patch.ts

================================================================================
PHASE 6 — Session/cart/locality SSOT hardening (server + client)
================================================================================
1) **Session**: use ONLY `connect.sid` cookie, never custom "sid".
   - Express bootstrap:
     app.set("trust proxy", 1);
     app.use(require("cookie-parser")());
     app.use(require("express-session")({
       secret: process.env.SESSION_SECRET || "dev_secret_change_me",
       resave: false,
       saveUninitialized: true,
       cookie: { httpOnly:true, sameSite:"lax", secure:process.env.NODE_ENV==="production", maxAge: 30*24*60*60*1000 }
     }));
     app.use(require("cors")({ origin: process.env.CORS_ORIGIN || true, credentials: true }));

   - ensureSession middleware:
     export default function ensureSession(req,res,next){
       if(!req.session) return next(new Error("Session not initialized"));
       (req as any).sessionId = req.sessionID; // alias only
       return next();
     }
     // REMOVE any res.cookie('sid', ...) and random guest id generation.

   - getCartOwnerId helper:
     export function getCartOwnerId(req:any){ return req.user?.id ?? req.sessionID; }

2) **Cart**:
   - On every mutation (POST/PATCH/DELETE), use `getCartOwnerId(req)`.
   - On GET /api/cart: call `consolidateAndClampCart(ownerId)` before returning.
   - Add DB UNIQUE index: `UNIQUE(ownerId, productId, COALESCE(variantId,''))`.
   - Storage API must include: getCartItemsByOwner, findCartItems, updateCartItemQty,
     removeCartItemsByProduct, removeCartItemById, createCartItem, getProductStock, rekeyCartItemOwner.

3) **Locality SSOT**:
   - Single server evaluator: `server/services/localityService.ts` → `getLocalityForRequest(req)`.
   - Single policy: `shared/availability.ts` → `computeEffectiveAvailability(productMode, userMode)`.
   - Client `useLocality()` fetches `/api/locality/status` and exposes `localityVersion` string.
   - All UI that references eligibility uses `computeEffectiveAvailability(...)` + `useLocality()`.

4) **Client API**:
   - `apiJson` must set `credentials:"include"`.
   - `addToCartApi` uses POST `/api/cart` with `{productId, qty, variantId?}` and handles 201/422.

================================================================================
PHASE 7 — Orphan route & legacy registration detection (server)
================================================================================
Add dev-only route introspection (mounted in dev only):
- Create `server/dev/routes-introspect.ts` exporting an Express handler that returns all registered routes.
- Add GET `/__routes__` in dev: list method+path; write to `audit/express-routes.json` via curl.
- Grep your `server/routes` folder; any file not present in `/__routes__` response is **orphan** → delete or register.

Example handler (minimal):

export function routesIntrospect(app:any){
  const list:any[]=[];
  app._router?.stack?.forEach((m:any)=>{
    if(m.route && m.route.path){ const methods = Object.keys(m.route.methods||{}); list.push({path:m.route.path, methods}); }
  });
  return list;
}

Mount in dev and `curl -s http://localhost:5000/__routes__ > audit/express-routes.json`

================================================================================
PHASE 8 — Lint/Type rules to freeze architecture (no backsliding)
================================================================================
1) ESLint (.eslintrc.*):

{
  "parser": "@typescript-eslint/parser",
  "plugins": ["@typescript-eslint","import","unused-imports"],
  "rules": {
    "no-restricted-imports": ["error", {
      "paths": [
        {"name":"server/routes/cart","message":"Legacy cart forbidden. Use server/routes/cart.v2.ts"},
        {"name":"server/lib/locality","message":"Use server/services/localityService.ts or shared/locality.ts"},
        {"name":"server/lib/localityChecker","message":"Merged into server/services/localityService.ts"},
        {"name":"server/locality/getLocalityForRequest","message":"Use server/services/localityService.ts"},
        {"name":"client/src/hooks/use-cart","message":"Use client/src/hooks/useCart.ts (V2 only)"},
        {"name":"src/lib/locality","message":"Use shared/locality.ts or client/src/hooks/useLocality.ts"}
      ]
    }],
    "no-restricted-syntax": [
      "error",
      { "selector":"CallExpression[callee.name='isLocal'], CallExpression[callee.name='isLocalMiles']",
        "message":"Use computeEffectiveAvailability + getLocalityForRequest (SSOT) instead." }
    ],
    "unused-imports/no-unused-imports": "error",
    "@typescript-eslint/no-explicit-any": "warn",
    "import/no-cycle": "warn"
  }
}

2) TSConfig hardening (tsconfig.json):
- "strict": true, "noImplicitAny": true, "noUncheckedIndexedAccess": true, "noFallthroughCasesInSwitch": true,
  "isolatedModules": true, "moduleResolution": "bundler"

3) ENV schema (server/config/env.ts) with Zod to validate all required envs (Stripe/Cloudinary/Resend/Neon).
- Fail fast on boot if invalid. Do NOT leak secrets to client.

================================================================================
PHASE 9 — Security & perf guardrails
================================================================================
1) Security:
   - Helmet in prod: `app.use(require('helmet')())`
   - Rate limit sensitive routes (auth/checkout): express-rate-limit
   - CORS: exact origin in prod, `credentials:true`
   - Stripe/Cloudinary/Resend keys: verify none appear in client bundle (grep build)
   - Disable source maps in prod or host privately
   - npm audit scripted pass (safe→scripted majors→force if tests pass), save reports in `audit/`

2) Performance:
   - Vite bundle analyzer: add `"analyze": "vite-bundle-visualizer"` script
   - `npx source-map-explorer dist/assets/*.js` → create `audit/bundle-report*.txt`
   - Tailwind purge: ensure single config; purge only needed content globs
   - Server: log p95 latencies per route and write `audit/latency-snapshot.json` after a smoke run

================================================================================
PHASE 10 — Rebuild, fix references, and run smoke
================================================================================
1) Type/build:
   npx tsc --noEmit
   npm run build

2) Stragglers (fix any remaining references to legacy):
   rg -n --no-heading -g '!node_modules' "server/routes/cart.ts|server/lib/locality|client/src/hooks/use-cart|/api/cart(?!\\.v2)" > audit/stragglers.txt

3) Start server; run cart/session smoke:

rm -f /tmp/c.sess
echo "=== Add #1 ===" && curl -i -c /tmp/c.sess -b /tmp/c.sess -H "Content-Type: application/json" -X POST http://localhost:5000/api/cart --data '{"productId":"TEST-1","qty":1}'
echo "=== Add #2 ===" && curl -i -c /tmp/c.sess -b /tmp/c.sess -H "Content-Type: application/json" -X POST http://localhost:5000/api/cart --data '{"productId":"TEST-1","qty":1}'
echo "=== GET cart ===" && curl -s -c /tmp/c.sess -b /tmp/c.sess http://localhost:5000/api/cart | head -120

- Expect qty=2, one cookie "connect.sid", stable owner across requests.
- Confirm no calls to legacy endpoints in logs.

================================================================================
PHASE 11 — CI guardrails (GitHub Actions) to block regressions
================================================================================
Create `.github/workflows/quality.yml`:

name: Quality Gate
on: [pull_request, push]
jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20' }
      - run: npm ci
      - run: npm run build --if-present
      - run: npx tsc --noEmit
      - run: npx eslint . --max-warnings=0
      - run: npx jscpd --min-tokens 50 --reporters json --ignore "**/node_modules/**,**/dist/**,**/build/**" --output audit --path .
      - run: npx knip --reporter summary
      - run: npx ts-prune -p tsconfig.json | tee audit/ts-prune.txt
      - run: npx madge --ts-config tsconfig.json --extensions ts,tsx,js,jsx --circular .
      - run: npx depcheck || true
      - name: Fail on clones or unused exports
        run: |
          test ! -s audit/ts-prune.txt
          test $(jq '.statistics.total' audit/jscpd-report.json) -eq 0

================================================================================
PHASE 12 — Final reports & commit
================================================================================
1) Re-run detectors to confirm:
   node scripts/find-duplicate-files.mjs
   npx jscpd --min-tokens 50 --reporters json --ignore "**/node_modules/**,**/dist/**,**/build/**" --output audit --path .
   npx knip --reporter json > audit/knip.json || true
   npx ts-prune -p tsconfig.json > audit/ts-prune.txt || true
   npx madge --ts-config tsconfig.json --extensions ts,tsx,js,jsx --circular --json . > audit/madge-circular.json || true
   npx depcheck --json > audit/depcheck.json || true
   npm ls --all > audit/npm-tree-after.txt || true
   git ls-files > audit/git-files-after.txt

2) Commit:
   git add .
   git commit -m "chore(cleanse): SSOT consolidation, purge duplicates/legacy, session/cart/locality hardening, CI guardrails"

What this adds (the “BEST” extras)

Orphan route detector (dev route introspection): catches server route files that aren’t actually mounted.

Hard ENV schema with Zod: stops misconfig at boot (Stripe/Cloudinary/Resend/Neon).

Security/perf guardrails: helmet, rate limits, precise CORS, bundle analysis, server p95 snapshots.

CI quality gate that blocks merges if clones/unused exports sneak back in.

TS & ESLint hardening: strict TS + import restrictions + forbidden pattern scans.

Sourcemap & secret hygiene: ensure secrets never reach client bundles; source maps gated.

Duplicate detection on two axes: content hashing and AST/token clones.

Automated import rewriting + file purging before deletion, so you don’t strand references.

Cart/session/locality SSOT reinforced across server & client with unified helpers and query invalidation.

If you want, I can also include ready-to-paste Playwright smoke tests for the add-to-cart + locality matrix and a Drizzle migration snippet that adds the uniqueness index and not-null/foreign-key constraints for cart_items.

You said:
yes add whatever else is essentials and rewrite whole message
ChatGPT said:
Thought for 21s

Absolutely. Here’s a fully rewritten, ultra-comprehensive “do-not-stop” master playbook you can paste into Replit. It performs a whole-repo cleanse + consolidation, enforces your SSOT architecture (locality/cart/auth), hardens session ownership (only connect.sid), adds DB invariants, security/perf guardrails, automated tests, and CI quality gates so the mess can’t grow back.

It’s tailored to your stack and layout (client/server/shared; React 18 + TS + Vite + TanStack Query; Node/Express + Drizzle + Postgres; Neon/Cloudinary/Stripe/Resend).

✅ Copy-paste into Replit (run sequentially)
You will execute a full codebase review, de-duplication, consolidation, SSOT hardening, and guardrail installation.
Follow these steps EXACTLY and do not stop until ALL SUCCESS CRITERIA are met.

================================================================================
SUCCESS CRITERIA (must ALL be true)
================================================================================
- No duplicate files (content or near-clone AST) remain.
- No duplicate implementations of cart, locality, geo, websocket, or auth.
- All imports point ONLY to canonical SSOT modules.
- Unused files/exports/routes removed; circular deps resolved; orphan routes eliminated.
- Session/cart owner unified on express-session `connect.sid` (no custom `sid` cookie anywhere).
- Cart consolidates duplicates and clamps to stock on read/write; V2 endpoints only.
- Locality SSOT used everywhere (server evaluator + shared availability policy).
- API inputs validated with Zod; consistent JSON error shape across server.
- DB invariants in place (UNIQUE keys, FK, CHECK qty>0).
- Security hardening (helmet, rate limits, precise CORS), perf reports (bundle + p95 routes).
- Typecheck/build/tests/linters pass; CI gates block regressions.

================================================================================
PHASE 0 — Branch, tools, and baseline snapshots
================================================================================
1) Branch
   git checkout -b chore/repo-cleanse-ssot-essentials

2) Dev tools
   npm i -D ts-morph @types/node jscpd knip ts-prune madge depcheck \
         eslint-plugin-import eslint-plugin-unused-imports \
         @typescript-eslint/parser @typescript-eslint/eslint-plugin \
         glob fast-glob cosmiconfig object-hash zod \
         vite-bundle-visualizer source-map-explorer pino pino-pretty

3) Baselines
   mkdir -p audit scripts codemods .github/workflows
   node -v > audit/node-version.txt
   npm -v > audit/npm-version.txt
   npm ls --all > audit/npm-tree-before.txt || true
   git ls-files > audit/git-files-before.txt
   rg -n --no-heading -g '!node_modules' . > audit/repo-grep-snapshot.txt
   # proceed even if build fails; we’ll fix during consolidation
   npx tsc --noEmit || true
   npm run build || true

================================================================================
PHASE 1 — Declare SSOT & bans (your architecture contract)
================================================================================
Create audit/ssot-allow-ban.json:

{
  "canonical": {
    "locality": [
      "shared/locality.ts",
      "shared/geo.ts",
      "shared/availability.ts",
      "server/services/localityService.ts",
      "client/src/hooks/useLocality.ts"
    ],
    "cart": [
      "server/routes/cart.v2.ts",
      "server/services/cartService.ts",
      "server/utils/cartOwner.ts",
      "client/src/hooks/useCart.ts",
      "client/src/lib/cartKeys.ts",
      "client/src/lib/cartApi.ts"
    ],
    "auth": [
      "server/auth.ts",
      "server/middleware/auth.ts",
      "client/src/hooks/use-auth.tsx"
    ],
    "fulfillment": [
      "shared/fulfillment.ts",
      "shared/availability.ts",
      "server/utils/fulfillment.ts"
    ],
    "websocket": [
      "server/websocket.ts"
    ],
    "envConfig": [
      "server/config/env.ts"
    ]
  },
  "legacyBan": [
    "server/routes/cart.ts",
    "server/lib/locality",
    "server/lib/localityChecker",
    "server/locality/getLocalityForRequest",
    "client/src/hooks/use-cart.tsx",
    "src/lib/locality.ts"
  ],
  "forbiddenPatterns": [
    "/api/cart(?!\\.v2)",           // legacy cart endpoints
    "\\bisLocal\\(", "\\bisLocalMiles\\(",  // ad-hoc locality
    "res\\.cookie\\(['\"]sid['\"]",         // custom sid cookie
    "document\\.cookie\\s*=\\s*['\"]sid",   // client sid writes
    "eval\\(", "new Function\\("            // ban dynamic code
  ],
  "preferPaths": [
    "^shared/",
    "^server/services/",
    "^server/utils/",
    "^client/src/hooks/",
    "^client/src/components/"
  ]
}

================================================================================
PHASE 2 — Detect duplicates (content + AST) & dead code
================================================================================
A) Content-duplicates
Create scripts/find-duplicate-files.mjs:

import fs from "fs"; import crypto from "crypto"; import fg from "fast-glob";
const files = fg.sync(["**/*.{ts,tsx,js,jsx,css,scss,md,json}", "!node_modules/**", "!dist/**", "!build/**", "!coverage/**"], { dot:true });
const map=new Map();
for(const f of files){const b=fs.readFileSync(f),h=crypto.createHash("sha1").update(b).digest("hex");(map.get(h)??map.set(h,[]).get(h)).push(f)}
const dups=[...map.entries()].filter(([,arr])=>arr.length>1).map(([h,arr])=>({hash:h,files:arr.sort()}));
fs.writeFileSync("audit/duplicate-files-content.json", JSON.stringify(dups,null,2));
console.log(`Content-duplicate groups: ${dups.length}`);

Run: node scripts/find-duplicate-files.mjs

B) AST/token clones
npx jscpd --min-tokens 50 --reporters json --ignore "**/node_modules/**,**/dist/**,**/build/**" --output audit --path .

C) Dead/unused/cycles/dep rot
npx knip --reporter json > audit/knip.json || true
npx ts-prune -p tsconfig.json > audit/ts-prune.txt || true
npx madge --ts-config tsconfig.json --extensions ts,tsx,js,jsx --circular --json . > audit/madge-circular.json || true
npx depcheck --json > audit/depcheck.json || true

================================================================================
PHASE 3 — Build consolidation plan (pick canonicals, mark deletes)
================================================================================
Create scripts/build-consolidation-plan.mjs:

import fs from "fs";
const cfg=JSON.parse(fs.readFileSync("audit/ssot-allow-ban.json","utf8"));
const dup=JSON.parse(fs.readFileSync("audit/duplicate-files-content.json","utf8"));
const jscpd=JSON.parse(fs.readFileSync("audit/jscpd-report.json","utf8"));
const knip=JSON.parse((()=>{try{return fs.readFileSync("audit/knip.json","utf8")}catch{return "{}"}})());
const prefer=cfg.preferPaths.map(p=>new RegExp(p)); const canonSet=new Set([].concat(...Object.values(cfg.canonical)));
const actions={replaceImportsThenDelete:[],deleteSafe:[],reviewManual:[]};
const rank=f=>{for(let i=0;i<prefer.length;i++)if(prefer[i].test(f))return i;return 999};
const pickCanon=files=>files.sort((a,b)=>rank(a)-rank(b)||a.length-b.length)[0];

// content dups
for(const g of dup){const canon=pickCanon(g.files);g.files.filter(f=>f!==canon).forEach(f=>actions.replaceImportsThenDelete.push({file:f,canonical:canon,reason:"content-duplicate"}));}
// AST clones
if(jscpd?.duplications){for(const d of jscpd.duplications){const files=d.files?.map(x=>x.filename)||[]; if(files.length<2)continue; const c=pickCanon(files); files.filter(f=>f!==c).forEach(f=>actions.replaceImportsThenDelete.push({file:f,canonical:c,reason:"ast-clone"}));}}
// knip unused
if(knip?.files){for(const f of Object.keys(knip.files)){if(!canonSet.has(f))actions.deleteSafe.push({file:f,reason:"knip-unused"});}}
// legacy banlist
cfg.legacyBan.forEach(p=>actions.replaceImportsThenDelete.push({file:p,canonical:null,reason:"legacy-banned"}));
fs.writeFileSync("audit/consolidation-plan.json", JSON.stringify(actions,null,2));
console.log("Plan -> audit/consolidation-plan.json");

Run: node scripts/build-consolidation-plan.mjs

================================================================================
PHASE 4 — Codemods: rewrite imports to canonicals, then purge files
================================================================================
A) Rewrite imports
Create codemods/replace-imports-to-canonical.ts:

import { Project } from "ts-morph"; import fs from "fs"; import path from "path";
const plan=JSON.parse(fs.readFileSync("audit/consolidation-plan.json","utf8"));
const reps=plan.replaceImportsThenDelete.filter((x:any)=>x.canonical);
const proj=new Project({ tsConfigFilePath:"tsconfig.json" });
proj.addSourceFilesAtPaths(["**/*.{ts,tsx}", "!node_modules/**", "!dist/**", "!build/**"]);
const norm=(p:string)=>p.replace(/\\/g,"/");
for(const sf of proj.getSourceFiles()){let changed=false;
  for(const imp of sf.getImportDeclarations()){
    const spec=norm(imp.getModuleSpecifierValue());
    for(const r of reps){
      const from=norm(r.file), to=norm(r.canonical), fromFile=from.split("/").pop();
      if(spec.endsWith(from)||spec.endsWith(fromFile!)){
        const rel=path.relative(path.dirname(norm(sf.getFilePath())), to).replace(/\\/g,"/");
        imp.setModuleSpecifier(rel.startsWith(".")?rel:"./"+rel); changed=true;
      }
    }
  }
  if(changed) sf.saveSync();
}
console.log("Imports rewritten to canonical targets.");

Run: npx ts-node codemods/replace-imports-to-canonical.ts

B) Purge non-canonicals & legacy
Create scripts/purge-files.mjs:

import fs from "fs";
const plan=JSON.parse(fs.readFileSync("audit/consolidation-plan.json","utf8"));
const rm=f=>{try{fs.rmSync(f,{force:true});console.log("Deleted:",f)}catch(e){console.warn("Could not delete",f,e?.message)}};
(plan.replaceImportsThenDelete||[]).forEach((x:any)=>{ if(x.canonical || x.reason==="legacy-banned") rm(x.file); });
(plan.deleteSafe||[]).forEach((x:any)=> rm(x.file));

Run: node scripts/purge-files.mjs

================================================================================
PHASE 5 — Annotate forbidden patterns (legacy endpoints, ad-hoc locality)
================================================================================
Create codemods/forbidden-patterns-patch.ts:

import { Project } from "ts-morph"; import fs from "fs";
const cfg=JSON.parse(fs.readFileSync("audit/ssot-allow-ban.json","utf8"));
const proj=new Project({ tsConfigFilePath:"tsconfig.json" });
proj.addSourceFilesAtPaths(["**/*.{ts,tsx}", "!node_modules/**"]);
for(const sf of proj.getSourceFiles()){
  let text=sf.getFullText(), changed=false;
  for(const pat of cfg.forbiddenPatterns){
    const re=new RegExp(pat,"g");
    if(re.test(text)){ text=text.replace(re,(m)=>`/* SSOT: FORBIDDEN ${pat} */ ${m}`); changed=true; }
  }
  if(changed){ sf.replaceWithText(text); sf.saveSync(); }
}
console.log("Forbidden patterns annotated.");

Run: npx ts-node codemods/forbidden-patterns-patch.ts

================================================================================
PHASE 6 — Session/cart/locality SSOT hardening (server+client)
================================================================================
1) Express session (ONLY connect.sid)
   app.set("trust proxy", 1);
   app.use(require("cookie-parser")());
   app.use(require("express-session")({
     secret: process.env.SESSION_SECRET || "dev_secret_change_me",
     resave: false, saveUninitialized: true,
     cookie: { httpOnly:true, sameSite:"lax", secure:process.env.NODE_ENV==="production", maxAge:30*24*60*60*1000 }
   }));
   app.use(require("cors")({ origin: process.env.CORS_ORIGIN || true, credentials: true }));

2) ensureSession middleware
   export default function ensureSession(req,res,next){
     if(!req.session) return next(new Error("Session not initialized"));
     (req as any).sessionId = req.sessionID; // alias only; DO NOT set custom cookies
     next();
   }
   # Search and remove any res.cookie('sid', ...), random guest IDs:
   rg -n --no-heading -g '!node_modules' -e "res\\.cookie\\(['\"]sid" -e "guest-" -e "cartOwnerId" > audit/sid-usages.txt

3) Single cart owner helper
   export function getCartOwnerId(req:any){ return req.user?.id ?? req.sessionID; }
   # Replace any usage of getUserIdFromReq/req.session.cartOwnerId/(req as any).sessionId reads with this helper.
   rg -n --no-heading -g '!node_modules' "getUserIdFromReq|session\\.cartOwnerId|\\(req as any\\)\\.sessionId" > audit/owner-usages.txt

4) One-time migration (optional if old `sid` carts exist)
   - If legacy `sid` cookie was used previously, implement migration to rekey items to `req.sessionID` and consolidate.

5) Cart V2 only
   - POST /api/cart { productId, qty, variantId? } -> upsert + clamp to stock
   - GET  /api/cart -> consolidate duplicates + clamp stock, return items+totals
   - DELETE /api/cart/product/:productId -> remove all items for owner/product
   - DELETE /api/cart/items/:id -> back-compat, owner-scoped
   - DB UNIQUE index: UNIQUE(ownerId, productId, COALESCE(variantId,''))
   - Storage funcs required: getCartItemsByOwner, findCartItems, getCartItemById,
     createCartItem, updateCartItemQty, removeCartItemById, removeCartItemsByProduct, getProductStock, rekeyCartItemOwner

6) Locality SSOT
   - Server: server/services/localityService.ts → getLocalityForRequest(req): { status, source, eligible, zip?, lat?, lon?, distanceMiles?, effectiveModeForUser, reasons[], ssotVersion, asOfISO }
   - Shared: shared/availability.ts → computeEffectiveAvailability(productMode, userMode) → 'ADD_ALLOWED'|'PICKUP_ONLY'|'SHIPPING_ONLY'|'BLOCKED'
   - Client: client/src/hooks/useLocality.ts fetches /api/locality/status, exposes `localityVersion` string; all UI relies on this + shared availability.

7) Client API wrapper
   - apiJson must always set `credentials:"include"`.
   - addToCartApi uses POST /api/cart with `{productId, qty, variantId?}` and handles 201/422; no legacy endpoints unless 404 fallback during rollout.

================================================================================
PHASE 7 — API request validation + JSON error shape
================================================================================
1) Create server/config/env.ts (Zod schema)
   - Validate required env for Neon, Stripe, Cloudinary, Resend; fail fast on boot.

2) Create server/middleware/jsonError.ts
   export function jsonError(err, _req, res, _next){
     const status=err.status||500;
     const payload={ error: err.code||err.name||"ERROR", message: err.message||"Unknown error" };
     if(process.env.NODE_ENV!=="production" && err.stack) payload.stack=err.stack;
     res.status(status).json(payload);
   }
   - Mount as last middleware.

3) Zod validate inputs for cart/checkout/auth routes; on failure → 400 with code "INVALID_BODY".

================================================================================
PHASE 8 — Storage invariants (Drizzle migrations)
================================================================================
Add migration ensuring data correctness:

-- 1) Unique cart row per (ownerId, productId, variantId)
CREATE UNIQUE INDEX IF NOT EXISTS cart_items_owner_prod_var_uidx
ON cart_items (owner_id, product_id, COALESCE(variant_id, ''));

-- 2) Quantity must be positive
ALTER TABLE cart_items
  ADD CONSTRAINT cart_qty_positive CHECK (qty > 0);

-- 3) FK integrity (adjust names to your schema)
ALTER TABLE cart_items
  ADD CONSTRAINT cart_items_owner_fk FOREIGN KEY (owner_id) REFERENCES owners(id) ON DELETE CASCADE;
ALTER TABLE cart_items
  ADD CONSTRAINT cart_items_product_fk FOREIGN KEY (product_id) REFERENCES products(id) ON DELETE CASCADE;

-- 4) Optional: materialized totals view for performance (if desired)

Run migration via Drizzle and re-generate types.

================================================================================
PHASE 9 — Orphan route detection (server)
================================================================================
Add dev-only route list:

// server/dev/routes-introspect.ts
export default function listRoutes(app:any){
  const out:any[]=[]; app._router?.stack?.forEach((m:any)=>{ if(m.route?.path){ out.push({ path:m.route.path, methods:Object.keys(m.route.methods||{}) }); }});
  return out;
}

Mount in DEV only:
if(process.env.NODE_ENV!=="production"){
  app.get("/__routes__", (_req,res)=> res.json(require("./dev/routes-introspect").default(app)));
}

Run:
curl -s http://localhost:5000/__routes__ > audit/express-routes.json
# Any server/routes/*.ts not represented here is orphaned -> delete or mount.

================================================================================
PHASE 10 — Lint/Type/Import guardrails (no backsliding)
================================================================================
.eslintrc.*:

{
  "parser": "@typescript-eslint/parser",
  "plugins": ["@typescript-eslint","import","unused-imports"],
  "rules": {
    "no-restricted-imports": ["error", {
      "paths": [
        {"name":"server/routes/cart","message":"Legacy cart forbidden. Use server/routes/cart.v2.ts"},
        {"name":"server/lib/locality","message":"Use server/services/localityService.ts or shared/locality.ts"},
        {"name":"server/lib/localityChecker","message":"Merged into server/services/localityService.ts"},
        {"name":"server/locality/getLocalityForRequest","message":"Use server/services/localityService.ts"},
        {"name":"client/src/hooks/use-cart","message":"Use client/src/hooks/useCart.ts (V2 only)"},
        {"name":"src/lib/locality","message":"Use shared/locality.ts or client/src/hooks/useLocality.ts"}
      ]
    }],
    "no-restricted-syntax": [
      "error",
      { "selector":"CallExpression[callee.name='isLocal'], CallExpression[callee.name='isLocalMiles']",
        "message":"Use computeEffectiveAvailability + getLocalityForRequest (SSOT)." }
    ],
    "unused-imports/no-unused-imports":"error",
    "@typescript-eslint/no-explicit-any":"warn",
    "import/no-cycle":"warn"
  }
}

tsconfig.json (hardening):
- "strict": true,
- "noImplicitAny": true,
- "noUncheckedIndexedAccess": true,
- "noFallthroughCasesInSwitch": true,
- "isolatedModules": true,
- "moduleResolution": "bundler",
- "paths": { "@shared/*":["shared/*"], "@server/*":["server/*"], "@client/*":["client/src/*"] }

================================================================================
PHASE 11 — Security & performance essentials
================================================================================
1) Security
   - app.use(require("helmet")());
   - Rate-limit auth and checkout routes (express-rate-limit).
   - CORS: in PROD set exact origin(s), credentials:true.
   - Verify secrets never in client bundle: after build, rg -n 'sk_live|cloudinary|resend' dist/ || true
   - Source maps: disable or host privately in PROD.

2) Structured logging
   - Use pino with request IDs:
     app.use((req,_res,next)=>{ req.id = req.id || crypto.randomUUID?.()||Date.now().toString(36); next(); });
     const pino = require("pino")(); app.use((req,res,next)=>{ res.locals.log = pino.child({ rid:req.id }); next(); });

3) Perf
   - Vite bundle: add "analyze": "vite-bundle-visualizer" and run once → output to audit/.
   - Server p95 route timing: wrap a middleware to measure and write audit/latency-snapshot.json after smoke.

================================================================================
PHASE 12 — Tests (unit + integration + e2e smoke)
================================================================================
1) Unit (Vitest)
   - shared/availability.spec.ts: full userMode×productMode matrix.
   - cartService.spec.ts: consolidate + clamp scenarios; add beyond stock → capped.

2) Integration (supertest)
   - POST /api/cart twice → GET /api/cart shows qty=2; deletes work; 422 on ineligible (reasons[] present).
   - /api/locality/status returns exact shape with ssotVersion.

3) E2E (Playwright)
   - Add to cart twice (connect.sid reused), cart badge increments, drawer shows qty=2.
   - Change ZIP to out-of-area → blocked UI and server 422; cart purge on GET.

================================================================================
PHASE 13 — Rebuild, fix stragglers, and runtime smoke
================================================================================
1) npx tsc --noEmit
2) npm run build
3) rg -n --no-heading -g '!node_modules' "server/routes/cart.ts|server/lib/locality|client/src/hooks/use-cart|/api/cart(?!\\.v2)" > audit/stragglers.txt
   # patch any leftovers to canonical

4) Start server & smoke:
rm -f /tmp/c.sess
echo "=== Add #1 ===" && curl -i -c /tmp/c.sess -b /tmp/c.sess -H "Content-Type: application/json" \
  -X POST http://localhost:5000/api/cart --data '{"productId":"TEST-1","qty":1}'
echo "=== Add #2 ===" && curl -i -c /tmp/c.sess -b /tmp/c.sess -H "Content-Type: application/json" \
  -X POST http://localhost:5000/api/cart --data '{"productId":"TEST-1","qty":1}'
echo "=== GET cart ===" && curl -s -c /tmp/c.sess -b /tmp/c.sess http://localhost:5000/api/cart | head -120
# Expect qty=2, ONLY connect.sid cookie, stable owner across requests.

================================================================================
PHASE 14 — CI quality gates (block regressions)
================================================================================
Create .github/workflows/quality.yml:

name: Quality Gate
on: [pull_request, push]
jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20' }
      - run: npm ci
      - run: npx tsc --noEmit
      - run: npm run build --if-present
      - run: npx eslint . --max-warnings=0
      - run: npx jscpd --min-tokens 50 --reporters json --ignore "**/node_modules/**,**/dist/**,**/build/**" --output audit --path .
      - run: npx knip --reporter summary
      - run: npx ts-prune -p tsconfig.json | tee audit/ts-prune.txt
      - run: npx madge --ts-config tsconfig.json --extensions ts,tsx,js,jsx --circular .
      - run: npx depcheck || true
      - name: Fail on clones or unused exports
        run: |
          test ! -s audit/ts-prune.txt
          test $(jq '.statistics.total' audit/jscpd-report.json) -eq 0

================================================================================
PHASE 15 — Final reports & commit
================================================================================
# re-run detectors to confirm cleanliness
node scripts/find-duplicate-files.mjs
npx jscpd --min-tokens 50 --reporters json --ignore "**/node_modules/**,**/dist/**,**/build/**" --output audit --path .
npx knip --reporter json > audit/knip.json || true
npx ts-prune -p tsconfig.json > audit/ts-prune.txt || true
npx madge --ts-config tsconfig.json --extensions ts,tsx,js,jsx --circular --json . > audit/madge-circular.json || true
npx depcheck --json > audit/depcheck.json || true
npm ls --all > audit/npm-tree-after.txt || true
git ls-files > audit/git-files-after.txt

git add .
git commit -m "chore(cleanse): SSOT consolidation, purge duplicates/legacy, session-cart-locality hardening, DB invariants, security/perf guardrails, CI quality gates"

Why these “essentials” matter (added vs. prior version)

DB invariants via Drizzle migrations (UNIQUE owner/product/variant, CHECK qty>0, FKs) stop duplicate rows and invalid qty at the data layer—not just in code.

Zod API validation + JSON error middleware make all server behavior predictable and safe.

Orphan route introspection prevents “dead routes” that never mount.

Structured logging (pino) + request IDs make debugging and tracing trivial.

Security hardening (helmet, precise CORS, rate limits) protects auth/checkout endpoints.

Perf visibility (bundle + p95 route timings) keeps regressions visible.

CI gates (jscpd/knip/ts-prune/madge) block duplicates, dead exports, and cycles from reappearing.

Strict TS & ESLint rules freeze the architecture: only canonical modules allowed; legacy patterns auto-flagged.